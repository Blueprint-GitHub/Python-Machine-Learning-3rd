{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtZwr4wyFMdHXHoNG2F77K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Blueprint-GitHub/Study_Note/blob/main/Machine_Learning_Engineering_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. 데이터 수집 및 준비**"
      ],
      "metadata": {
        "id": "3XPpHG_Df8TD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1) 데이터를 수집하기 전에 답변해야 할 질문**"
      ],
      "metadata": {
        "id": "Qk5DEYUemdr4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Snw2H3WfBU7"
      },
      "outputs": [],
      "source": [
        "1. 데이터를 구할 수 있는가?\n",
        "  1) 데이터 접근성      : 필요한 데이터가 존재한다면 물리적, 계약적, 윤리적, 비용 측면 접근 가능한가?\n",
        "  2) 데이터 사용과 공유 : 데이터 소스를 구입하거나 재사용해야 하는 경우 그 데이터의 사용 및 공유 조건은 무엇인지\n",
        "                          데이터 공급 업체와의 새로운 라이센스 계약이 필요하지는 않은가?\n",
        "  3) 법적 규정 준수     : 데이터가 저작권, 개인정보보호법, 기타 법적 규범에 의해 보호되는지\n",
        "                          그렇다면 저작권 소유자는 누구이며 허가를 받을수 있는가?\n",
        "  4) 민감한 정보 처리   : 데이터에 개인정보나 기밀로 분류된 민감한 내용이 담겨있는지 검토해야 하며\n",
        "                          필요한 경우 데이터를 익명화하거나 개인 식별 정보를 제거해야 한다.\n",
        "  5) 데이터 공유 필요성 : 모델과 함께 데이터를 공유해야 하는 경우, 이에 대한 규정과 제약을 파악하고 준비해야한다.\n",
        "\n",
        "2. 데이터 세트의 크기가 충분히 큰가?\n",
        "  - 특히 모델 품질(정확도) 요구사항이 엄격한 경우 그 품질을 달성하기 위해서 얼마나 많은 데이터가 필요한지\n",
        "    미리 알기 어렵다. 그러므로 충분한 양의 데이터가 제공되는지, 새로운 데이터를 어느정도의 빈도로 얻을 수 있는지\n",
        "    등을 확인해야 한다.\n",
        "  - 충분한 데이터를 확보했는지 알 수 있는 좋은 방법은 학습 곡선을 그려보는 것인데 추가적인 데이터가 학습 곡선의\n",
        "    향상을 이루지 못한다면 추가 견본으로부터 얻을 수 있는 이득이 감소하고 있다고 추정할 수 있고\n",
        "    학습 과정에 더 복잡한 알고리즘을 사용하거나 특성공학을 시도해보는 것을 고려해 볼 수 있다.\n",
        "  - 경험 법칙에 기반해 문제에 필요한 훈련 데이터셋의 수를 추정할 수도 있는데. 자주 인용되는 숫자는\n",
        "    특성 개수의 10배, 클래스 개수의 100~1000배, 훈련 가능한 매개변수의 10배(신경망)이다.\n",
        "  - 또한 데이터가 있다고 해서 그 데이터를 전부 사용해야 하는 것은 아니다. 실제로는 계층화된 샘플링,\n",
        "    체계적인 샘플링과 같은 샘플링 전략으로 얻은 일부 샘플만으로도 더 좋은 결과를 얻을 수 있고\n",
        "    성능 손실 없이도 모델을 더 빨리 훈련시킬 수 있기 때문이다.\n",
        "\n",
        "3. 데이터를 사용할 수 있나?\n",
        "  - 머신러닝에 사용하는 데이터 세트는 항상 깔끔해야 한다. 그러므로 데이터에 결측값, 중복 항목이 있거나\n",
        "    불필요하거나 혹은 실제 상황을 대표하지 못하는 데이터가 섞여있는 경우(동물 사진은 대부분 여름을 배경으로 한다.)\n",
        "    이를 적절히 처리하거나 제거하여 모델이 일반화되고 편향되지 않도록 만들어야 한다.\n",
        "\n",
        "4. 데이터를 이해할 수 있나?\n",
        "  - 데이터의 각 속성(feature)이 어디에서 왔으며 그것이 정확히 무엇을 나타내는지 이해하는 것도 매우 중요하다.\n",
        "    예측하려는 변수(target)이 특성 벡터에 교묘하게 포함되어 있다면, 모델은 훈련 데이터셋에 쉽게 과적합되고\n",
        "    전혀 일반화되지 않을 수 있다. 이를 데이터 누출(data leakage)또는 목표 누출(target leakage)라고 한다.\n",
        "    예를 들어 주택 가격 예측을 위한 데이터셋에 부동산 중개인의 수수료가 있다고 하면, 그 수수료는 집값이\n",
        "    정해지고 난 다음 생긴 특성이기 때문에 데이터 누출이 발생해 모델이 일반화되지 못하는 것이다.\n",
        "\n",
        "5. 데이터를 신뢰할 수 있나?\n",
        "  - 데이터 세트가 수집된 과정을 신뢰할 수 있나? 대규모 데이터셋의 레이블링은 대부분 아웃소싱을 하게 되는데\n",
        "    이렇게 수집된 데이터 세트가 신뢰할 수 없는 것이라면 모델의 성능 또한 매우 떨어지게 될 것이다.\n",
        "  - 또한 레이블의 지연된 특성이나 간접적인 특성에도 영향을 받을 수 있다. 예를 들어 현재 데이터 셋을 가지고\n",
        "    6개월 뒤 고객이 이탈할지 아닐지를 예측하는 문제라면 그 기간 사이에 알 수 없는 많은 이벤트가 발생하므로\n",
        "    지연된 레이블은 데이터의 신뢰성을 떨어트린다. 또 좋아요/싫어요 와 같은 레이블은 직접적인 관심 지표라고\n",
        "    할 수 있지만, 고객이 링크만 클릭했거나 홈페이지에 얼마간 머물다가 간 경우는 실제적인 관심이 아닌\n",
        "    약간의 관심을 나타내는 간접적인 레이블인 것이다.\n",
        "  - 데이터의 또 다른 불안정성 원인은 피드백 루프 형성이다. 예를 들어 콘텐츠 감성 분석과 추천 모델에서\n",
        "    간접 레이블(클릭 수)만 있다고 가정할 때 모델은 간접 레이블을 바탕으로 특정 콘텐츠를 추천하게 되고\n",
        "    그 콘텐츠의 데이터가 모델에 계속 축적되면서 한정적인 콘텐츠의 데이터만 모델이 학습하게 되는 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2) 일반적인 데이터 관련 문제**"
      ],
      "metadata": {
        "id": "PMS8a1dCmgRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1. 높은 비용\n",
        "  - 데이터를 얻는 데 비용이 들지만, 특히 사람이 레이블링해야 하는 경우에는 매우 많은 시간과 비용이 발생한다.\n",
        "    예를 들어 위성 사진을 보고 사물을 annotation 한다면 사진 한 장에도 꽤 오랜 시간이 걸릴 것이다.\n",
        "    따라서 잘 설계된 레이블링 도구를 만들어 사용하는 경우가 많다. 예를 들어 SOTA 모델을 사용해서 잡음이 있는\n",
        "    사전 레이블링을 사용하고, 인간 레이블러는 적절한 워크플로우에 따라 잘못된 레이블만 수정하는 것이다.\n",
        "\n",
        "2. 데이터의 품질\n",
        "  - 데이터 품질은 모델의 성능에 영향을 아주 크게 미치므로 원시 데이터와 레이블링 품질에 주의를 기울여야 한다.\n",
        "    원시 데이터 품질은 잡음, 편향, 낮은 예측력, 오래된 견본, 특잇값, 누출과 같이 다양한 요소들에 영향을 받는다.\n",
        "\n",
        "  1) 잡음(noise)\n",
        "    - 잡음은 데이터의 질을 저하시키는 요소로, 흐린 이미지, 손상된 텍스트, 잡음이 섞인 오디오, 누락된 값 등을 뜻한다.\n",
        "      이러한 잡음은 특히 데이터 셋의 크기가 작을 때 모델이 과적합되는 주요 원인이지만 반대로 큰 데이터 셋\n",
        "      에서는 여러 견본에 의해서 정규화되어 모델이 작은 부분 집합에 의존되지 않도록 하는 효과도 있다.\n",
        "\n",
        "  2) 편향(bias)\n",
        "    - 선택 편향(selection bias) : 쉽게 구할 수 있고, 편리하고, 비용 효율적인 데이터 소스를 선택하도록\n",
        "                                  왜곡하는 경향, 백인 데이터셋에서 훈련된 업스케일링 모델은 흐릿한 흑인 사진을\n",
        "                                  백인으로 바꾸어버리는 것과 같이 일부 데이터에 대해 편향된 예측을 할 수 있다.\n",
        "    - 자기 선택 편향(self-selection bais) : 여론 조사 데이터에서 흔하게 발생하는 편향 문제로, 실제 분포를 반영하지\n",
        "                                            못하는 데이터 셋이 생성될 수 있다. 예를 들어 특정 지역의 사람들을\n",
        "                                            대상으로 정치 성향을 물으면 한 쪽 성향의 사람들이 편향되게 나타날 것이고\n",
        "                                            이는 현실을 전혀 반영하지 못하는 것이다.\n",
        "    - 생략된 변수 편향(omitted variable bias) : 중요한 예측 변수가 데이터에 누락되었을 때 발생하는 문제이다.\n",
        "                                                이는 훈련할때는 문제가 없었지만 시간이 흐르며 매우 중요한 특성이\n",
        "                                                생겼을때(경쟁자가 새로운 것을 시도했다던지) 쉽게 발생한다.\n",
        "    - 후원/자금 편향(sponsorship / funding bias) : 어떠한 이해관계로 인해 데이터 셋에 사실을 과장하거나\n",
        "                                                   축소한 데이터가 많이 포함되는 경우 모델의 성능은 최적화되지 못한다.\n",
        "    - 샘플링 편향(sampling bias) : 모델이 배포되고 실제로 운영하는 환경에서의 입력 분포가 훈련에 사용된 sample의 분포와\n",
        "                                   다를 수 있다. 예를 들어 20가지의 주제를 각각 5%씩 데이터 셋에 포함시켜서 훈련했는데\n",
        "                                   실제로 들어오는 입력은 한 두가지 주제가 80%를 차지한다면 모델은 예상보다 큰 오차를\n",
        "                                   보이게 될 것이다.\n",
        "    - 고정관념 편향(stereotype bias) : 데이터 셋에 편견이 들어있는 경우 발생하는 편향으로 성별, 인종, 환경 등에 따라\n",
        "                                       모델이 편향된 출력을 보이는 것을 말한다(예를 들어 의사 - 남자, 간호사 - 여자 등)\n",
        "    - 체계적인 값 왜곡(systematic value distortion) : 일반적으로 측정값이나 이미지 등에서 발생하는 편향으로 저품질\n",
        "                                                      이미지로 모델을 훈련하여 실제로 사용하는 고품질 이미지에 대한\n",
        "                                                      예측 성능이 나쁘게 나타나는 현상을 말한다.\n",
        "    - 실험자 편향(experimenter bias) : 설문 조사 등에서 조사를 설계한 사람 혹은 응답자의 신념이나 가설에 대한 확증 편향\n",
        "                                       에 의해 정직하거나 투명하지 못한 데이터 셋이 생성되는 것을 말한다.\n",
        "    - 레이블링 편향(labeling bias) : 편향된 프로세스나 사람이 레이블링을 할 때 발생하는 문제로, 레이블을 하는 사람에 따라\n",
        "                                     특정 방향으로 잘못 레이블링 하거나 특정 주제에 대해 더 많이 레이블링하여 레이블 분포\n",
        "                                     문제가 발생하는 것을 말한다.\n",
        "\n",
        "    # 편향을 피하는 방법\n",
        "    - 선택 편향 : 데이터 소스를 선택한 이유에 대한 체계적인 질문을 한다. 그 이유가 단순함이나 낮은 비용으로 드러났다면\n",
        "                  그 데이터에서는 좋은 예측을 얻을 수 없을 확률이 높다.\n",
        "    - 자기 선택 편향 : 이를 완전히 제거할 수는 없으며, 최대한 간결하고 명확한 질문을 통해 개선할 수 있다.\n",
        "    - 생략된 변수 편항 : 불필요하다고 생각하는 특성까지 모두 포함해 훈련한다. 이렇게 하면 물론 특성 벡터가 커지는 단점이\n",
        "                         있지만 적절한 정규화와 모델의 학습 능력을 통해 해결할 수 있다. 또한 어떤 중요한 데이터를 얻는 것이\n",
        "                         어렵다면 이를 대신할 수 있는 대용 변수(proxy variable)를 추가해본다.\n",
        "    - 후원 편향 : 데이터 소스와 데이터의 소유자가 데이터를 제공하려는 동기를 주의 깊게 조사하면 후원 편향을 줄일 수 있다.\n",
        "    - 샘플링 편향 : 훈련 데이터의 샘플링 비율을 실제 데이터 셋과 유사하게 만들어 훈련한다.\n",
        "    - 고정관념 편향 : 편견이 발생하지 않도록 모든 그룹의 분포를 고르게 조정한다.\n",
        "    - 체계적인 값 왜곡: 여러 측정 장치를 사용하거나 측정 기기나 관찰 기기의 출력을 비교할 수 있는 사람을 고용한다.\n",
        "    - 실험자 편향 : 객관식 질문보다는 개방형(주관식) 질문을 선택한다. 설문 조사를 설계할 때 다른 사람의 검증을 통하여\n",
        "                    완화할 수 있다.\n",
        "    - 레이블링 편향 : 동일한 견본을 여러 레이블러에게 할당하여 피할 수 있다. 이 과정을 통해 특정 레이블러가 편향된\n",
        "                      레이블링을 진행하고 있지는 않은지 관찰할 수 있다.\n",
        "\n",
        "3. 낮은 예측력(low predictive power)\n",
        "  - 모델을 아무리 복잡하게 만들어도 목표했던 정확도에 미치지 못하는 상황이 발생할 수 있다.\n",
        "    이때는 창의성을 발휘해서 가능한 한 많은 추가 특성들을 설계하고 간접 데이터 소스를 고려해볼 수 있다.\n",
        "\n",
        "4. 오래된 견본\n",
        "  - 모델을 구축하고 환경에 배포하면 시간이 흐르며 모델의 성능이 점점 나빠지는 경우를 볼 수 있는데\n",
        "    이것은 개념 이동(Concept drift)이 발생하여 특성 벡터와 레이블과의 관계가 근본적으로 달라졌기 때문이다.\n",
        "    이를 해결하기 위해서는 오래된 샘플을 지속적으로 제거하고 새로운 샘플을 데이터 셋에 추가해 재훈련해야 한다.\n",
        "\n",
        "5. 특잇값\n",
        "  - 대부분의 샘플과 달라 보이는 특잇값을 가진 샘플은 훈련을 어렵게 만드는데, 특히 데이터 셋이 작을때 이것을\n",
        "    제외하는 것은 바람직하지 않기 때문이다. 또한 특잇값에 대해서도 강건한 예측을 하기 위해서 복잡한 모델을 사용하는 것도\n",
        "    비용 효율적인 측면에서 좋지 못하기 때문에 이를 잘 처리해야 한다.(RobustScaler, Hyperparameter Tuning 등)\n",
        "\n",
        "6. 데이터 누출(data leakage)\n",
        "  - 목표 누출(target leakage)라고도 하는 데이터 누출은 사용하지 말아야 하는 정보가 훈련 데이터에 포함되어\n",
        "    모델이 훈련 데이터 셋에 대해 지나치게 낙관적인 예측(좋은 성능)을 보이게 되는 현상을 말한다."
      ],
      "metadata": {
        "id": "XRouLju3miux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3) 좋은 데이터란?**"
      ],
      "metadata": {
        "id": "2WKXSLEA5Tpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1. 모델링에 사용할 수 있을 만큼 충분한 정보를 포함하고 있다.\n",
        "2. 모델로 수행하려는 작업에 대한 넓은 적용 범위를 갖고 있다.\n",
        "3. 운영 환경에서의 실제 입력을 반영한다.\n",
        "4. 가능한 한 편향이 없다.\n",
        "5. 모델 자체의 예측 결과가 아니다.(피드백 루프의 결과물이 없다.)\n",
        "6. 일관된 레이블이 있다.(레이블링 편향이 없다.)\n",
        "7. 일반화를 할 수 있을 만큼 충분히 크다."
      ],
      "metadata": {
        "id": "U96ZLXbY6ql6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4) 상호 작용 데이터 처리**"
      ],
      "metadata": {
        "id": "SCyCM_UmD_xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "상호 작용 데이터(interaction data)란 시스템과 사용자 간의 상호 작용에서 수집할 수 있는 데이터로\n",
        "어떤 링크의 클릭 데이터나 웹사이트에 머무른 시간, 별점과 같은 사용자 피드백과 같은 데이터를 의미한다.\n",
        "이러한 데이터들은 알고리즘을 더욱 개선하고 개인화하는 데 사용할 수 있으며.\n",
        "상호 작용의 맥락, 해당 맥락에서의 사용자 행동, 상호 작용의 결과와 같은 정보들을 포함하는 데이터를\n",
        "좋은 상호 작용 데이터라고 할 수 있다."
      ],
      "metadata": {
        "id": "jUHnwVcZECUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5) 데이터 누출의 원인**"
      ],
      "metadata": {
        "id": "5kNC4Wm83Ejt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " 1. 타겟이 특성의 함수인 경우\n",
        "   - 한 국가의 GDP를 예측하고 싶을때 데이터에 인구수와 1인당 GDP 열이 있으면 그 두가지를 가지고\n",
        "     완벽하게 GDP를 예측할 수 있는 것과 같은 경우 혹은 연봉을 예측하는 모델을 훈련하고 싶은데\n",
        "     데이터에 월급에 해당하는 열이 있는 경우.\n",
        " 2. 타겟이 특성에 숨어 있는 경우\n",
        "   - 고객의 성별을 예측하고 싶을때 데이터에 성별과 나이로 고객의 그룹을 묶은 열이 있다면 그 열에서\n",
        "     데이터 누출이 발생하여 모델이 완벽한 예측을 수행하게 될 것이다.\n",
        " 3. 특성이 미래를 반영하는 경우\n",
        "   - 6개월 뒤 대출금 상환 여부를 예측하는 모델을 만들때 데이터에 연체 알림 횟수를 카운트한 열이 있다면\n",
        "     그 데이터 셋이 배포되고 나서 들어오는 입력은 모두 연체 알림 횟수가 0일 것이고 연체 알림값이 1 이상인\n",
        "     고객을 죄다 아니오로 분류해버릴 수 있다."
      ],
      "metadata": {
        "id": "i2m3jk6Z3HIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6) 데이터 분할**"
      ],
      "metadata": {
        "id": "SJmnKmeZ6MJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "- 머신러닝 프로젝트에서는 보통 데이터 셋을 훈련 세트, 검증 세트, 테스트 세트로 분류하며\n",
        "  각각 약 80%/10%/10% 의 범위에서 분할하는 것이 일반적이다. 모델은 훈련 세트를 바탕으로 하여\n",
        "  검증 세트를 통해 적절한 하이퍼 파라미터를 찾는 과정을 거치고, 마지막으로 배포 전에 테스트 세트로 평가한다.\n",
        "  보통 검증 세트와 훈련 세트를 통칭하여 홀드아웃 세트(Holdout set)라고 하며, 다음과 같은 규칙에 의해 분할돼야 한다.\n",
        "\n",
        "  1) 원시 데이터에 분할을 적용한다.\n",
        "  2) 분할 전에 데이터를 랜덤화한다.(섞는다)\n",
        "  3) 검증 세트와 테스트 세트는 동일한 분포를 따른다.\n",
        "  4) 분할 도중 누출을 방지한다.\n",
        "\n",
        "  또한 시계열 데이터(time-series data)를 다룰때는 데이터를 나누고 섞는 것에 주의를 기울여야 하는데, 데이터가\n",
        "  시간 순서에 따른 정렬 상태를 유지하고 있어야 하기 때문이다. 시계열 데이터 셋을 마구잡이로 섞으면 데이터가\n",
        "  손상되고 학습이 불가능할 수 있다.\n",
        "\n",
        "- 데이터 누출은 데이터 수집부터 모델 평가에 이르기까지의 모든 단계에서 발생할 수 있는데, 데이터를 분할하는 과정에서도\n",
        "  이러한 누출이 발생할 수 있다. 먼저 그룹 누출(group leakage)가 발생할 수 있다. 만약 뇌 질환을 겪는 환자 A의 MRI 이미지가\n",
        "  100장이 있을때 무작위로 섞고 분할하면 검증 세트나 테스트 세트에 이 사진이 들어가 모델이 환자 A를 인식하고 완벽하게\n",
        "  예측을 할 수 있게 된다. 따라서 그룹 분할(group partitioning)과 같은 방법을 사용해 데이터 누출을 막아야 한다.\n",
        "  scikit-learn의 GroupKFlod, LeaveoneGroupout 메서드를 이용한다."
      ],
      "metadata": {
        "id": "dEa4Ryn86fBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7) 결측 속성 처리**"
      ],
      "metadata": {
        "id": "VDdcL_nw81Bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "- 속성의 결측값을 처리하는 일반적인 접근 방식은 다음과 같다.\n",
        "  1) 데이터 세트에서 누락된 속성을 제거한다(df.dropna())\n",
        "  2) 결측된 속성값을 처리할 수 있는 알고리즘을 사용한다(tree-based model)\n",
        "  3) 데이터 대체 기술을 사용한다.(Imputation)\n",
        "\n",
        "1. 결측값 대체 기술\n",
        "  - 결측값 대체 기술에는 해당 열(feature)의 평균(mean)이나 중앙값(median)을 채워넣는 방법이 주로 사용되고\n",
        "    정상적이지 않은 값을 넣어서 모델이 이를 학습하게 하거나, 고급 기술로는 회귀 모델로 결측값을 채워넣을 수도 있다.\n",
        "    또한 결측값의 존재 유무(0,1) 자체를 알려주는 이진 지시자 특성(binary indicator)를 추가할 수도 있는데\n",
        "    특정 조건에서만 결측값이 발생하거나, 다른 특성과 관련이 있는 경우 이진 지시자 특성을 추가해 결측 정보를 유지하고\n",
        "    모델이 더욱 복잡한 패턴을 학습할 수 있게 할 수도 있다.\n",
        "\n",
        "2. 대체 중 누출\n",
        "  - 만약 imputation이나 regression으로 결측값을 대체할때 전체 데이터 셋을 사용한다면 검증 데이터와 테스트 데이터에서\n",
        "    얻은 정보로 훈련 데이터 셋을 오염시키게 되는 것과 같으므로 이를 주의하고 먼저 raw data를 분할한 뒤에\n",
        "    결측값 대체를 수행해야 한다."
      ],
      "metadata": {
        "id": "n7w-ast-82z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **8) 데이터 증강(Data augmentation)**"
      ],
      "metadata": {
        "id": "v93FyCzyAk1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "일부 데이터 유형(특히 이미지)의 경우 추가 레이블링 없이 원본 데이터를 뒤집거나 자르거나, 확대하거나, 색상의 변화를 주는\n",
        "방법으로 조금씩 조작하면서 수많은 데이터를 생성할 수 있는데, 이 과정을 데이터 증강(data augmentation)이라고 한다.\n",
        "\n",
        "1. 이미지 데이터 증강\n",
        "  1) 뒤집기 : 이미지에 특정 방향이 있거나 위 아래가 있는 경우 그 축은 뒤집어서는 안된다.\n",
        "  2) 회전 : 양방향으로 이미지를 회전시켜 데이터를 늘릴 수 있지만 그 각도는 신중하게 선택해야 한다.\n",
        "  3) 확대/축소 : 다양한 크기의 객체를 인식할 수 있게 하지만 중요한 정보가 잘려나가지 않도록 주의해야 한다.\n",
        "  4) 자르기 : 여러 번 랜덤하게 적용할 수 있지만 잘라내고 남은 이미지에는 관심 대상의 상당 부분이 남아있어야 한다.\n",
        "  5) 색상 변화 : 색상 변화, 대비 변경, 잡음 추가와 같은 방법을 말한다.\n",
        "  6) 혼합(mixup) : 두 개의 이미지(클래스에 관계 없이)를 혼합하는 방법으로 생각보다 효과가 좋다.\n",
        "\n",
        "2. 텍스트 데이터 증강\n",
        "  1) 동의어 변환 : 문장에서 임의의 단어를 의미가 가까운 동의어로 바꾸는 방법\n",
        "    - K최근접 이웃, BERT와 같은 방법으로 변환할 단어와 가장 가까이 있는 동의어를 찾을 수 있다.\n",
        "  2) 상위어 사용 : 문장에서 임의의 단어를 좀 더 상위어(고양이 -> 포유류)로 바꾸는 방법\n",
        "  3) 문장 재구성 : 문맥이 크게 바뀌지 않는 범위 내에서 문장의 단어 순서를 약간 변경할 수 있다.\n",
        "  4) 가우스 잡음 추가 : 단어나 문서가 embedding으로 표현되는 경우 일정 잡음을 추가할 수 있다.\n",
        "  5) 역번역 : 영어 문장을 한글로 번역한 뒤 다시 영어로 번역하여 원본 텍스트와 다른 문장이 생성되면\n",
        "              그 문장에 동일한 레이블을 할당해 데이터 셋에 추가한다.\n",
        "\n",
        "3. 오디오 및 비디오 데이터 증강\n",
        "  - 배경 소음 추가, 필터링, 시간 이동, 속도 가•감속, 피치 변경, 색 밸런스 변경 등의 방법이 있다."
      ],
      "metadata": {
        "id": "UyjKZ7EDAmeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9) 클래스 불균형**"
      ],
      "metadata": {
        "id": "6TtaEu52JVwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "클래스 불균형(class imbalance)은 실제 환경에서 매우 흔하게 발생하는 문제이며, 학습 알고리즘과 관계 없이\n",
        "모델의 성능에 상당한 영향을 미칠 수 있는 데이터의 내재 조건이다.\n",
        "\n",
        "1. 오버샘플링 (imblearn.over_sampling import SMOTE, ADASYN)\n",
        "  - 소수 클래스의 샘플을 기반으로 합성 샘플을 생성해 비중을 높이는 방법으로 합성 소수 오버샘플링 기법(SMOTE)과\n",
        "    적응적 합성 표본법(ADASYN)이 있다. 둘 다 가장 가까운 k개의 이웃을 찾아 합성 샘플을 만드는데\n",
        "    SMOTE는 그 샘플과 이웃들 사이의 임의의 점을 선택해 합성 샘플을 만드는 반면,\n",
        "    ADASYN는 그 샘플의 이웃 중 다수 클래스에 속하는 비율이 높은 샘플에 더 많은 합성 샘플을 생성해\n",
        "    소수 클래스와 다수 클래스의 경계선을 더욱 뚜렷하게 만들어준다.\n",
        "\n",
        "2. 언더샘플링 (imblearn.under_sampling import TomekLinks, ClusterCentroids)\n",
        "  - 다수 클래스의 샘플을 랜덤하게 제거하거나 토멕 링크(Tomek link), 군집 기반 언더샘플링과 같은\n",
        "    전략을 사용할 수 있다. 토멕 링크는 서로 다른 클래스에 속하는 한 쌍의 데이터를 묶어서 다수 클래스에\n",
        "    속한 샘플을 지우는 방법으로 노이즈를 제거하고 데이터의 경계를 더욱 명확하게 만들어 준다.\n",
        "    군집 기반 언더샘플링은 K-최근접 이웃과 같은 방법으로 다수 클래스에 속한 샘플을 여러 군집으로 나누는 방법으로\n",
        "    각 군집의 대표 샘플(중심)을 사용해 데이터셋의 크기를 줄인다.\n",
        "\n",
        "3. 하이브리드 전략\n",
        "  - ADASYN으로 오버샘플링 하고 토멕링크를 언더샘플링 하거나 군집 기반 언더 샘플링과 SMOTE를 결합하는 등의\n",
        "    하이브리드 전략은 각각의 샘플링 기법의 이점을 모두 얻을 수 있다. 그러나 언제나 효과적이진 않으며\n",
        "    데이터의 특성에 따라 다르게 작용할 수 있으므로 적절한 실험과 검증 과정이 필요하다."
      ],
      "metadata": {
        "id": "TkEig-jlJXcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **10) 데이터 샘플링 전략**"
      ],
      "metadata": {
        "id": "wJDfISWsP1lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "데이터 셋이 충분히 큰 경우, 전체 데이터로 작업하는 것이 항상 실용적이거나 필요한 것은 아니므로\n",
        "학습에 충분한 정보가 포함된 더 적은 데이터 샘플을 만들면 더욱 효율적으로 훈련할 수 있다.\n",
        "\n",
        "1) 단순 랜덤 샘플링(Simple Random Sampling)\n",
        "  - 흔히 랜덤 샘플링이라고 부르며, 단순하고 빠른 방법이지만 클래스 균형을 유지하지 못할 수 있으므로\n",
        "    데이터 셋이 비교적 균일할 때 사용해야 한다.\n",
        "\n",
        "2) 체계적인 샘플링(systematic sampling)\n",
        "  - 간격 샘플링(interval sampling)이라고도 부르며, 전체 데이터 셋에서 일정 간격마다 데이터를 하나씩\n",
        "    샘플링하는 방법이다. 랜덤 샘플링보다 더 좋은 샘플을 얻을 확률이 높지만 데이터에 주기적이거나\n",
        "    반복적인 패턴이 있는 경우에 사용하기는 부적절하므로 데이터 구조를 사전에 파악해야 한다.\n",
        "\n",
        "3) 계층화된 샘플링(stratified sampling)\n",
        "  - 데이터 셋을 그룹(계층)으로 나눈 다음, 각 계층에서 샘플을 랜덤하게 선택하는 방법으로, 계층의 크기에\n",
        "    비례해서 샘플을 선택한다. 이런 특징 때문에 불균형 데이터셋에서 특히 유용하지만 적절하지 못한 기준으로\n",
        "    데이터를 나누는 경우 성능이 매우 나빠질 수 있다."
      ],
      "metadata": {
        "id": "aN7rCPwgS1Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **11) 데이터 저장**"
      ],
      "metadata": {
        "id": "ERRfj7pbVH4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1. 데이터 형식\n",
        "  - 일반적으로 CSV 또는 TSV로 저장하는데 이 경우 모든 샘플은 하나의 파일에 저장된다.\n",
        "    반면에 XML이나 JSON 파일 모음에는 파일당 하나의 샘플이 저장된다.\n",
        "    범용 형식 외에도 Weka 라이브러리에서 제공하는 ARFF나 LIBSVM 파일 형식도 있다.\n",
        "    또한, 다양한 프로그래밍 언어가 데이터 직렬화(data serialization) 기능을 제공하는데 파이썬에서는\n",
        "    Pickle, R에서는 saveRDS와 readRDS 같은 내장 함수가 있으며 자바는 java.io.Serializable 인터페이스를\n",
        "    제공한다.\n",
        "\n",
        "2. 데이터 저장소 레벨\n",
        "  - 파일 시스템 : 저장소의 기본이 되는 단계이며 쉽게 지우거나 덮어쓸 수 있고, 로컬에 있거나 네트워크에\n",
        "                  연결되어 있을 수 있다. 파일 시스템 수준의 저장소는 데이터 공유와 보관(NAS), 데이터 보호와\n",
        "                  같은 목적에 사용될때 적합하다.\n",
        "  - 객체 저장소 : 객체 저장소는 자체적으로 정의된 API(응용 프로그래밍 인터페이스)를 의미하며 데이터의\n",
        "                  기본 단위는 이미지, 사운드, 비디오 파일과 같은 객체(object) 데이터이다.\n",
        "                  Amazon S3, Google Cloud Storage와 같은 플랫폼이 있다.\n",
        "  - 데이터베이스 : 데이터 베이스의 기본 단위는 행(row)으로 행에는 고유 ID가 있으며 열에는 값이 있다.\n",
        "                   행은 파일 시스템이나 객체 저장소의 다른 곳에 저장된 데이터를 참조할 수 있다.\n",
        "                   Oracle, MySQL과 같은 데이터베이스 관리 시스템들은 저장과 검색을 위한 빠른 병렬 접근을 통해\n",
        "                   구조화된 데이터를 빠르게 확장가능하게 저장할 수 있게 해주는 동시에 데이터 베이스를 조작하기\n",
        "                   위한 인터페이스인 쿼리 언어(SQL)를 제공한다.\n",
        "  - 데이터레이크 : 일반적으로 객체 블롭(blobs ; Binary Large Object Blob)이나 파일의 형태로된 자연 형식이나\n",
        "                   원시 형식 데이터를 저장하는 저장소이다. 일반적으로 데이터 레이크에는 원본 데이터에서 변환을\n",
        "                   거친 데이터베이스, 로그, 중간 데이터와 같은 여러 소스의 데이터를 비정형적으로 집계한 데이터가\n",
        "                   저장된다.\n",
        "\n",
        "3. 데이터 버전 관리\n",
        "  - 데이터를 여러 위치에 보관하고 업데이트하는 경우 버전을 추적하는 것이 매우 중요한데, 특히 자동화된 방식으로\n",
        "    데이터를 수집하고 모델을 업데이트하는 경우 시간이 흐름에 따라서 모델 성능이 저하되지는 않는지, 고품질의\n",
        "    레이블이 지속적으로 제공되고 있는지 등을 점검하면서 버전을 배포해야 한다.\n",
        "\n",
        "    레벨 0 : 데이터 버전 관리를 하지 않는다.\n",
        "    레벨 1 : 훈련 시점의 스냅숏으로 데이터 버전 관리를 한다.\n",
        "    레벨 2 : 데이터와 코드 모두 하나의 자산으로 버전을 관리한다.\n",
        "    레벨 3 : 특화된 데이터 버전 관리 솔루션을 사용하거나 구축한다.\n",
        "\n",
        "4. 문서화와 메타데이터\n",
        "  - 머신러닝 프로젝트를 운영 환경으로 이관하고 나면 점점 이전 프로젝트에 대한 기억이 희미해지게 된다.\n",
        "    따라서 데이터와 모델에 대한 정보를 다른 사람이 올바르게 이해하고 사용할 수 있도록 자세한 정보들을\n",
        "    문서화해놓는 것이 필수적이며. 아래와 같은 내용을 담고 있어야 한다.\n",
        "\n",
        "    - 데이터의 의미\n",
        "    - 데이터 수집 방법, 데이터 생성에 사용된 방법\n",
        "    - 레이블러에 대한 지침과 품질 관리 방법\n",
        "    - 훈련/검증/테스트 데이터 분할 관련 세부 사항\n",
        "    - 모든 전처리 단게에 대한 세부 정보\n",
        "    - 제외된 데이터에 대한 설명\n",
        "    - 데이터 저장 형식\n",
        "    - 속성이나 특성의 유형(각 속성이나 특성에 대한 허용값)\n",
        "    - 샘플의 수\n",
        "    - 가능한 레이블값이나 수치적 허용 범위"
      ],
      "metadata": {
        "id": "UpviJGSGVJON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **12) 데이터 처리 모범 사례**"
      ],
      "metadata": {
        "id": "fJhc0Md3oS4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1. 재현성(reproducibility)\n",
        "  - 재현성은 데이터 수집과 준비를 포함한 모든 단계에서 중요한 요소이며 데이터를 처리하는 과정에서\n",
        "    수동으로 처리하거나 정규표현식을 쓰거나 명령 줄 셸에 포함된 강력한 도구를 사용하는 경우에\n",
        "    재현성이 떨어질 수 있으므로 파이썬 스크립트와 라이브러리를 활용한 파이프라인을 구축하여\n",
        "    작업 중에 변경사항을 추적할 수 있도록 하고 재현성을 보장해야 한다.\n",
        "\n",
        "2. 데이터 우선, 알고리즘은 그 다음\n",
        "  - 학계와는 달리 산업계에서는 광범위하고 고품질의 데이터를 더 많이 얻는데 대부분의 시간을 소비한다.\n",
        "    데이터 증강과 같은 기술을 잘 구현하면 하이퍼 파라미터 튜닝이나 더 복잡한 모델 구조를 찾는데 시간을\n",
        "    쓰는 것 보다 더 높은 품질의 모델을 얻을 확률이 높아진다."
      ],
      "metadata": {
        "id": "esVtn2aboUpw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}