{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "코드 링크 : https://github.com/qkqkfldis1/kaggle_book_bengaliai/blob/main/train_code_bengaliai_notebook.ipynb"
      ],
      "metadata": {
        "id": "S2gpGvhxiXBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    - 시작 단계\n",
        "      • 대회에 참가할때는 반드시 평가 방법을 숙지해야 한다.\n",
        "        왜냐하면 평가 방법(지표)에 따라 문제 해결 전략이 달라지기 때문이다."
      ],
      "metadata": {
        "id": "xj3kYvy8Bd0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **모델 전처리**"
      ],
      "metadata": {
        "id": "Jbb9jq8FRwhR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **요약**"
      ],
      "metadata": {
        "id": "1igyijd3R1ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "제공되는 파일:\n",
        "train.csv\\\n",
        "train_image_data_0.parquet\\\n",
        "train_image_data_1.parquet\\\n",
        "train_image_data_2.parquet\\\n",
        "train_image_data_3.parquet"
      ],
      "metadata": {
        "id": "ebdMOVORWUCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install iterative-stratification"
      ],
      "metadata": {
        "id": "vFwGOvK9TLUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "\n",
        "data_dir = \"../input/\"\n",
        "files_train = [f\"train_image_data_{fid}.parquet\" for fid in range(4)]\n",
        "F = os.path.join(data_dir, files_train[0])\n",
        "df_train_images = pd.read_parquet(F)\n",
        "\n",
        "#이미지 파일(pd 데이터프레임)을 피클(pkl)데이터로 저장\n",
        "for fname in files_train:\n",
        "    F = os.path.join(data_dir, fname)\n",
        "    df_train_images = pd.read_parquet(F)\n",
        "    img_ids = df_train_images[\"image_id\"].values # 샘플 번호\n",
        "    img_array = df_train_images.iloc[:, 1:].values # 이미지 데이터 (137*236)\n",
        "    for idx in tqdm(range(len(df_train_images))):\n",
        "        img_id = img_ids[idx]\n",
        "        img = img_array[idx]\n",
        "        joblib.dump(img, f\"../input/train_images/{img_id}.pkl\")"
      ],
      "metadata": {
        "id": "QoANPJ2YWMVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "\n",
        "df_train = pd.read_csv('../input/train.csv')  # 훈련 데이터를 불러온다.\n",
        "\n",
        "# StratifiedKFold를 위해 이미지 id와 target 값을 나눈다.\n",
        "X = df_train['image_id'] #.values로 넘파이 배열로 변환 가능.\n",
        "y = df_train[[\"grapheme_root\", \"vowel_diacritic\", \"consonant_diacritic\"]]\n",
        "\n",
        "# MultilabelStratifiedKFold로 3개의 레이블을 5개의 폴드로 나눈다.\n",
        "mskf = MultilabelStratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
        "df_train[\"fold\"] = -1\n",
        "for i, (trn_idx, vld_idx) in enumerate(mskf.split(X, y)):\n",
        "    df_train.loc[vld_idx, \"fold\"] = i\n",
        "df_train[\"fold\"] = df_train[\"fold\"].astype(int)\n",
        "\n",
        "# 랜덤하게 섞인 폴드가 추가된 파일을 저장\n",
        "df_train.to_csv(\"../input/df_folds.csv\", index=False)\n",
        "\n",
        "# 다시 그 파일을 불러오고\n",
        "df_folds = pd.read_csv(\"../input/df_folds.csv\")\n",
        "\n",
        "#훈련폴드는 80% 검증 폴드는 20% 사용.\n",
        "trn_fold = [0,1,2,3]\n",
        "vld_fold = [4]\n",
        "trn_idx = df_folds.loc[df_folds[\"fold\"].isin(trn_fold)].index\n",
        "vld_idx = df_folds.loc[df_folds[\"fold\"].isin(vld_fold)].index\n",
        "\n",
        "trn_df = df_folds.loc[trn_idx]\n",
        "vld_df = df_folds.loc[vld_idx]"
      ],
      "metadata": {
        "id": "Brp-XfHvS45N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TF DATA API\n",
        "import tensorflow as tf\n",
        "\n",
        "img_height = 137\n",
        "img_width = 236\n",
        "image_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "def preprocess_img(img_id, label, is_training=True):\n",
        "    img_file = tf.io.read_file(f\"../input/train_images/{img_id}.pkl\")\n",
        "    img = tf.io.decode_raw(img_file, out_type=tf.uint8)\n",
        "    img = tf.reshape(img, [img_height, img_width, 1])\n",
        "    img = 255 - img  # 흑백 반전\n",
        "    img = tf.image.grayscale_to_rgb(img)  # 그레이스케일 이미지를 RGB로 변환\n",
        "\n",
        "    # 증강을 위한 함수 (Albumentations 대신 TensorFlow 함수 사용)\n",
        "    def augment(img):\n",
        "        img = tf.image.random_crop(img, size=[image_size, image_size, 3])\n",
        "        img = tf.image.random_flip_left_right(img)\n",
        "        # 추가적인 증강 기능을 여기에 구현 가능.\n",
        "        return img\n",
        "\n",
        "    img = augment(img) if is_training else tf.image.resize(img, [image_size,\n",
        "                                                                 image_size])\n",
        "    return img, label\n",
        "\n",
        "def get_dataset(df, is_training=True):\n",
        "    img_ids = df['image_id'].values\n",
        "    labels = df[['grapheme_root', 'vowel_diacritic',\n",
        "                 'consonant_diacritic']].values\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((img_ids, labels))\n",
        "    dataset = dataset.map(lambda img_id, label:\n",
        "                          preprocess_img(img_id, label,is_training),\n",
        "                          num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    if is_training:\n",
        "        dataset = dataset.shuffle(1024).repeat()\n",
        "    return dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "trn_dataset = get_dataset(trn_df, is_training=True)\n",
        "vld_dataset = get_dataset(vld_df, is_training=False)"
      ],
      "metadata": {
        "id": "4Zx4uYGdR4Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **전체 과정**"
      ],
      "metadata": {
        "id": "QtpyulOKR1vT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. 파일 불러오고 탐색하기**\n"
      ],
      "metadata": {
        "id": "SfEpN1VgCg5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"../input/\"\n",
        "files_train = [f\"train_image_data_{fid}.parquet\" for fid in range(4)]\n",
        "->  ['train_image_data_0.parquet',\n",
        "    'train_image_data_1.parquet',\n",
        "    'train_image_data_2.parquet',\n",
        "    'train_image_data_3.parquet']\n",
        "\n",
        "F = os.path.join(data_dir, files_train[0])\n",
        "\n",
        "df_train_images = pd.read_parquet(F) #parquet 확장자 파일을 읽어들이면 pd로 불러옴\n",
        "df_train_images.head()\n",
        "\n",
        "\n",
        "#이미지를 몇 개 불러와서 탐색한다.\n",
        "idx = 0\n",
        "img = df_train_images.iloc[idx, 1:].values.astype(np.uint8)\n",
        "# img = 255 - img # 이미지 색 반전\n",
        "\n",
        "plt.imshow(img.reshape(137, 236), cmap=\"gray\")  # HEIGHT, WIDTH 순서\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ixyePdVuFX-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Target의 분포 탐색하고 폴드 만들기**"
      ],
      "metadata": {
        "id": "_xIIeUfUDa13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "3개의 target 데이터를 불러오고 bar를 plot해서 모든 target이 적절하게 분포되어 있는지 확인한다.\n",
        "\n",
        "df_train = pd.read_csv('../input/train.csv')\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "df_train[\"grapheme_root\"].value_counts().sort_index().plot.bar()\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "df_train[\"vowel_diacritic\"].value_counts().sort_index().plot.bar()\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "df_train[\"consonant_diacritic\"].value_counts().sort_index().plot.bar()\n",
        "\n",
        "\n",
        "이때 클래스별 분산이 균일하지 않다면 Stratified Fold\n",
        "를 사용할 수 있고, 만약 Target Label이 여러개라면 iterstrat라이브러리의\n",
        "ml_stratifiers.MultilabelStratifiedKFold 를 사용 할 수 있다.\n",
        "\n",
        "아래와 같이 처음에 폴드를 만들고 폴드를 추가한 pd 데이터프레임을\n",
        "csv로 저장해두면 처음 한 번만 만들고 계속 재사용할 수 있다.\n",
        "\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "\n",
        "#grapheme_root, vowel_diacritic, consonant_diacritic이 Target 데이터임.\n",
        "X = df_train[[\"image_id\", \"grapheme_root\", \"vowel_diacritic\", \"consonant_diacritic\"]].values[:, 0]\n",
        "y = df_train[[\"image_id\", \"grapheme_root\", \"vowel_diacritic\", \"consonant_diacritic\"]].values[:, 1:]\n",
        "\n",
        "mskf = MultilabelStratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
        "df_train[\"fold\"] = -1\n",
        "for i, (trn_idx, vld_idx) in enumerate(mskf.split(X, y)):\n",
        "    df_train.loc[vld_idx, \"fold\"] = i\n",
        "df_train[\"fold\"] = df_train[\"fold\"].astype(int)\n",
        "\n",
        "df_train.to_csv(\"../input/df_folds.csv\", index=False)\n",
        "\n",
        "아래와 같이 섞고 fold 번호를 할당한다.\n",
        "fold는 원본 데이터셋의 레이블 비율을 반영하여 분할된다.\n",
        "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic  fold\n",
        "0  Train_0             15                9                    5     2\n",
        "1  Train_1            159                0                    0     3\n",
        "2  Train_2             22                3                    5     1\n",
        "3  Train_3             53                2                    2     0\n",
        "4  Train_4             71                9                    5     4"
      ],
      "metadata": {
        "id": "kkJ-oYneFddZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. 데이터 파일 전처리**\n",
        "데이터가 너무 많은 경우에 이를 판다스 데이터프레임으로 읽어들이면\\\n",
        "시간 손해가 발생하므로 넘파이 배열이나 pickle 파일 형태로 바꿔서 저장하고\\\n",
        "읽는 방식을 취하면 모델 학습 시간을 단축시킬 수 있다.\n",
        "\n",
        "예를 들면 아래와 같이 간단하게 할 수 있다."
      ],
      "metadata": {
        "id": "wdyYQj5VGaTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터프레임 생성\n",
        "df = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\n",
        "# Pickle 파일로 저장\n",
        "df.to_pickle('filename.pkl')\n",
        "\n",
        "# Pickle 파일 로드\n",
        "df_loaded = pd.read_pickle('filename.pkl')\n",
        "# 로드된 데이터 확인\n",
        "print(df_loaded)\n",
        "\n",
        "\n",
        "#실제 코드\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "\n",
        "for fname in files_train:\n",
        "    F = os.path.join(data_dir, fname)\n",
        "    df_train_images = pd.read_parquet(F)\n",
        "    img_ids = df_train_images[\"image_id\"].values # 샘플 번호\n",
        "    img_array = df_train_images.iloc[:, 1:].values # 이미지 데이터 (137*236)\n",
        "    for idx in tqdm(range(len(df_train_images))):\n",
        "        img_id = img_ids[idx]\n",
        "        img = img_array[idx]\n",
        "        joblib.dump(img, f\"../input/train_images/{img_id}.pkl\")\n",
        "\n",
        "\n",
        "tqdm 이란? 실시간 진행상황을 나타내주는 라이브러리\n",
        "\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "for i in tqdm(range(10)):\n",
        "    time.sleep(1)\n",
        "    print(i)\n",
        " 10%|█         | 1/10 [00:01<00:09,  1.00s/it]0\n",
        " 20%|██        | 2/10 [00:02<00:08,  1.00s/it]1\n",
        " 30%|███       | 3/10 [00:03<00:07,  1.00s/it]2\n",
        " 40%|████      | 4/10 [00:04<00:06,  1.00s/it]3\n",
        " 50%|█████     | 5/10 [00:05<00:05,  1.00s/it]4\n",
        " 60%|██████    | 6/10 [00:06<00:04,  1.00s/it]5\n",
        " 70%|███████   | 7/10 [00:07<00:03,  1.00s/it]6\n",
        " 80%|████████  | 8/10 [00:08<00:02,  1.00s/it]7\n",
        " 90%|█████████ | 9/10 [00:09<00:01,  1.00s/it]8\n",
        "100%|██████████| 10/10 [00:10<00:00,  1.00s/it]9\n",
        "\n",
        "\n",
        "joblib 이란? 대규모 데이터 구조를 빠르게 저장하고 불러오는 라이브러리\n",
        "사이킷런 모델을 저장하거나 불러올때도 사용된다..\n",
        "import joblib\n",
        "모델 저장: joblib.dump(model, 'model_filename.pkl')\n",
        "모델 불러오기: model = joblib.load('model_filename.pkl')\n",
        "\n",
        "또한 병렬 처리를 지원한다. (Parallel , delayed 메서드 사용)\n",
        "from joblib import Parallel, delayed\n",
        "results = Parallel(n_jobs=-1)(delayed(my_function)(i) for i in my_list)\n",
        "\n",
        "Parallel = n_jobs를 사용해 cpu 코어 사용 개수 할당\n",
        "delayed = 함수 실행을 지연시켜 병렬처리 하게 만듬\n",
        "즉, 위 코드는 my_list에 있는 인수를 모두 my_function에 넣으며 실행시키는 것을\n",
        "병렬로 처리하는 것을 구현한 예시임.\n",
        "\n",
        "# 모델을 훈련할때 n_jobs = -1 하는것도 내부적으로 joblib를 알아서 구현하는것임."
      ],
      "metadata": {
        "id": "d0P2IYA-FoCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. 훈련, 검증 세트 만들기**\n"
      ],
      "metadata": {
        "id": "8iyywUz4IgQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"../input/train.csv\")\n",
        "df_train[\"fold\"] = pd.read_csv(\"../input/df_folds.csv\")[\"fold\"]\n",
        "\n",
        "trn_fold = [0,1,2,3]\n",
        "vld_fold = [4]\n",
        "trn_idx = df_train.loc[df_train[\"fold\"].isin(trn_fold)].index\n",
        "vld_idx = df_train.loc[df_train[\"fold\"].isin(vld_fold)].index\n",
        "\n",
        "trn_df = df_train.loc[trn_idx]\n",
        "vld_df = df_train.loc[vld_idx]\n",
        "\n",
        "사전 훈련된 모델을 사용하기 위해 일자로 늘여서 벡터로 저장한 이미지를\n",
        "3차원(RGB)로 변환해야 한다.\n",
        "\n",
        "csv = trn_df.reset_index()\n",
        "img_ids = csv[\"image_id\"].values\n",
        "img_height = 137\n",
        "img_width = 236\n",
        "\n",
        "index = 0\n",
        "img_id = img_ids[index]\n",
        "img = joblib.load(f\"../input/train_images/{img_id}.pkl\")\n",
        "img = img.reshape(img_height, img_width).astype(np.uint8)\n",
        "img = 255 - img # 흑백 반전이 성능이 더 좋았음.\n",
        "img = img[:, :, np.newaxis]\n",
        "img = np.repeat(img, 3, 2) # img, repeat, axis\n",
        "\n",
        "#확인\n",
        "plt.imshow(img)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "L90XPAHuFyvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. 데이터 증강**\n",
        "albumentations는 특히 이미지 데이터를 증강시켜주는 강력한 라이브러리이다.\\\n",
        "물론 어떤 데이터 증강 기법을 사용할지,\n",
        "얼마나 할지도 하이퍼파라미터 이므로 많은 실험을 통해 효과적인 방법을 찾아야 한다."
      ],
      "metadata": {
        "id": "D9XxfAcfMWwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import albumentations as A\n",
        "image_size = 224\n",
        "train_transform = A.Compose(\n",
        "    [\n",
        "        A.RandomResizedCrop(height=image_size, width=image_size),\n",
        "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=0.05, p=0.5),\n",
        "        A.RGBShift(r_shift_limit=0.05, g_shift_limit=0.05, b_shift_limit=0.05, p=0.5),\n",
        "        A.RandomBrightnessContrast(p=0.5),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "valid_transfrom = A.Compose(\n",
        "    [\n",
        "        A.Resize(height=image_size, width=image_size),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "Fysh0EhGF26N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. 훈련**\n"
      ],
      "metadata": {
        "id": "CyiGaxFwQRgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Label을 넘파이 배열로 읽어들이고.. (val_df도 포함)\n",
        "label_1 = trn_df.iloc[index].grapheme_root\n",
        "label_2 = trn_df.iloc[index].vowel_diacritic\n",
        "label_3 = trn_df.iloc[index].consonant_diacritic"
      ],
      "metadata": {
        "id": "sTf0se2qF8zG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **모델 훈련**"
      ],
      "metadata": {
        "id": "7oYadNF8bcg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# 모델 불러오기 및 마지막 레이어 교체\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(186, activation='softmax')(x)\n",
        "model = tf.keras.Model(inputs = base_model.input, outputs = x)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer = Adam(lr=0.001),\n",
        "              loss = CategoricalCrossentropy(),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# 스케줄러 설정\n",
        "scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.5,\n",
        "    patience=7,\n",
        "    verbose=1,\n",
        "    mode='max',\n",
        "    min_lr=0.0001\n",
        ")\n",
        "\n",
        "# 모델을 GPU로 설정 (사용 가능한 경우)\n",
        "model = model.cuda() if tf.test.is_gpu_available() else model"
      ],
      "metadata": {
        "id": "9sSd8VmDF_Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CUT-MIX (데이터 증강)**\n"
      ],
      "metadata": {
        "id": "tx5yAtVXfsnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = np.int(W * cut_rat)\n",
        "    cut_h = np.int(H * cut_rat)\n",
        "\n",
        "    # uniform\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "\n",
        "for inputs, targets in tqdm(trn_loader):\n",
        "    inputs = inputs.cuda()\n",
        "    targets = targets.cuda()\n",
        "    break\n",
        "\n",
        "lam = np.random.beta(1.0, 1.0)\n",
        "rand_index = tf.random.shuffle(inputs.size()[0])\n",
        "targets_gra = targets[:, 0]\n",
        "targets_vow = targets[:, 1]\n",
        "targets_con = targets[:, 2]\n",
        "shuffled_targets_gra = targets_gra[rand_index]\n",
        "shuffled_targets_vow = targets_vow[rand_index]\n",
        "shuffled_targets_con = targets_con[rand_index]\n",
        "\n",
        "bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
        "inputs[:, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
        "lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (inputs.size()[-1] * inputs.size()[-2]))\n",
        "plt.imshow(inputs[10].permute(1, 2, 0).cpu())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F53JyNYlGDYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mix-up (데이터 증강)**\n"
      ],
      "metadata": {
        "id": "JUJOhDkMgfI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lam: Lambda\n",
        "lam = np.random.beta(1.0, 1.0)\n",
        "print(lam)\n",
        "rand_index = tf.random.shuffle(inputs.size()[0])\n",
        "\n",
        "shuffled_targets_gra = targets_gra[rand_index]\n",
        "shuffled_targets_vow = targets_vow[rand_index]\n",
        "shuffled_targets_con = targets_con[rand_index]\n",
        "\n",
        "batch_size = inputs.size()[0]\n",
        "index = tf.random.shuffle(batch_size)\n",
        "\n",
        "inputs = lam * inputs + (1 - lam) * inputs[index, :]\n",
        "\n",
        "plt.imshow(inputs[10].permute(1, 2, 0).detach().cpu())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gBaKUhweGF5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stochastic Weight Averaging (SWA)**   \n",
        "딥 러닝에서 모델 가중치의 평균을 사용해 단일 모델의 성능을\\\n",
        "향상 시키는 앙상블 기법\n",
        "swa_start_epoch는 일반적으로 전체 훈련 에포크의 중간 지점 이후로 설정하는 것이 좋다.\n"
      ],
      "metadata": {
        "id": "-n3aUfIthT3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SWA 콜백 정의\n",
        "class SWA(Callback):\n",
        "    def __init__(self, swa_epoch):\n",
        "        super(SWA, self).__init__()\n",
        "        self.swa_epoch = swa_epoch\n",
        "        self.swa_weights = None\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch == self.swa_epoch:\n",
        "            self.swa_weights = self.model.get_weights()\n",
        "        elif epoch > self.swa_epoch:\n",
        "            current_weights = self.model.get_weights()\n",
        "            n = epoch - self.swa_epoch + 1\n",
        "            for i in range(len(current_weights)):\n",
        "                self.swa_weights[i] = (self.swa_weights[i] * (n - 1) + current_weights[i]) / n\n",
        "\n",
        "# 모델 훈련\n",
        "swa_callback = SWA(swa_epoch=5)  # SWA를 5번째 에폭 이후부터 적용\n",
        "model.fit(x_train, y_train, epochs=10, callbacks=[swa_callback])\n",
        "\n",
        "# SWA 평균 가중치로 모델 설정\n",
        "model.set_weights(swa_callback.swa_weights)"
      ],
      "metadata": {
        "id": "5qVOMSMYGIB1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}