{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPMQKdIFpZybTfo3h3NJGt0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["VAE (Variational Auto Encoder) : 변이형 오토 인코더 (연속적인 이미지 배열 생성, 표정 변환 / 애니메이션)\\\n","GAN (Generative Adversarial Network) : 생성적 적대 신경망 (더욱 사실적인 이미지 생성)"],"metadata":{"id":"SYSoC4nGcnuf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tcBcd_FPblok"},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","latent_dim = 2 # 잠재 공간의 차원 : 2D 평면\n","\n","# VAE 인코더 네트워크\n","encoder_inputs = keras.Input(shape = (28, 28, 1))\n","x = layers.Conv2D(\n","    32, 3, activation = 'relu', strides = 2, padding = 'same')(encoder_inputs)\n","x = layers.Conv2D(64, 3, activation = 'relu', strides = 2, padding = 'same')(x)\n","x = layers.Flatten()(x)\n","x = layers.Dense(16, activation = 'relu')(x)\n","z_mean = layers.Dense(latent_dim, name = \"z_maen\")(x)\n","z_log_var = layers.Dense(latent_dim, name = \"z_log_var\")(x)\n","encoder = keras.Model(encoder_inputs, [z_mean,z_log_var], name = \"encoder\")"]},{"cell_type":"code","source":["# 잠재 공간 샘플링\n","import tensorflow as tf\n","\n","class Sampler(layers.Layer): # 사용자 정의 레이어\n","    def call(self, z_mean, z_log_var):\n","        batch_size = tf.shape(z_mean)[0]\n","        z_size = tf.shape(z_mean)[1]\n","        epsilon = tf.random.normal(shape = (batch_size, z_size)) # 정규분포\n","        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"],"metadata":{"id":"AQaBBxR7hl8S","executionInfo":{"status":"ok","timestamp":1698970466664,"user_tz":-540,"elapsed":2,"user":{"displayName":"김태식","userId":"11264777984025639378"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#VAE 디코더 네트워크 latent = 잠재 변수\n","\n","latent_inputs = keras.Input(shape = (latent_dim,)) # z를 입력으로 사용? z = 잠재공간의 어느 포인트\n","x = layers.Dense(7*7*64, activation = 'relu',)(latent_inputs) #인코더 Flatten층과 동일한 크기로 지정\n","x = layers.Reshape((7, 7, 64))(x) # Flatten층 복구\n","x = layers.Conv2DTranspose(  # 컨브넷 층 2개 복구\n","    64, 3, activation = 'relu', strides = 2, padding = 'same')(x)\n","x = layers.Conv2DTranspose(\n","    32, 3, activation = 'relu', strides = 2, padding = 'same')(x)\n","decoder_outputs = layers.Conv2D(\n","    1, 3, activation = 'sigmoid', padding = 'same')(x) # 크기는 마지막으로 28,28,1로 돌아옴\n","decoder = keras.Model(latent_inputs, decoder_outputs, name = 'decoder')"],"metadata":{"id":"XxXNVHezh_--","executionInfo":{"status":"ok","timestamp":1698970759278,"user_tz":-540,"elapsed":1,"user":{"displayName":"김태식","userId":"11264777984025639378"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["\"\"\" VAE모델(사용자 정의 모델)을 만든다, fit()메서드는 지도 학습에만 초첨이\n","맞춰져 있으므로 일반적인 지도 학습이 아닌 경우에는 아래와 같이\n","사용자 정의 훈련 스텝(fit)을 만들어 사용해야 한다. \"\"\"\n","\n","class VAE(keras.Model):\n","    def __init__(self, encoder, decoder, **kwargs):\n","        super().__init__(**kwargs)\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.sampler = Sampler()\n","        # 에포크 마다 손실 평균을 추적\n","        self.total_loss_tracker = keras.metrics.Mean(name = 'total_loss')\n","        self.reconstruction_loss_tracker = keras.metrics.Mean(\n","            name = 'reconstruction_loss')\n","        self.kl_loss_tracker = keras.metrics.Mean(name = 'kl_loss')\n","\n","# 각 에포크가 완료된 후 모델이 손실을 재설정 할 수 있도록 metrcis속성에 손실을 나열\n","    @property\n","    def metrics(self):\n","        return [self.total_loss_tracker,\n","                self.reconstruction_loss_tracker,\n","                self.kl_loss_tracker]\n","\n","    def train_step(self, data):\n","        with tf.GradientTape() as tape:\n","            z_mean, z_log_var = self.encoder(data)\n","            z = self.sampler(z_mean, z_log_var)\n","            reconstruction = decoder(z)\n","            reconstruction_loss = tf.reduce_mean(\n","                tf.reduce_sum(\n","                    keras.losses.binary_crossentropy(data, reconstruction),\n","                    axis = (1, 2)\n","                )\n","            )\n","            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n","            total_loss = reconstruction_loss + tf.reduce_mean(kl_loss)\n","        grads = tape.gradient(total_loss, self.trainable_weights)\n","        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n","        self.total_loss_tracker.update_state(total_loss)\n","        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n","        self.kl_loss_tracker.update_state(kl_loss)\n","        return {\n","            \"total_loss\" : self.total_loss_tracker.result(),\n","            \"reconstruction_loss\" : self.reconstruction_loss_tracker.result(),\n","            \"kl_loss\": self.kl_loss_tracker.result()\n","        }"],"metadata":{"id":"hiy5kb3DjHpe","executionInfo":{"status":"ok","timestamp":1698972296763,"user_tz":-540,"elapsed":1,"user":{"displayName":"김태식","userId":"11264777984025639378"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n","mnist_digits = np.concatenate([x_train, x_test], axis = 0) #훈련에 전체 데이터 사용\n","mnist_digits = np.expand_dims(mnist_digits, -1).astype('float32') / 255\n","\n","vae = VAE(encoder, decoder)\n","vae.compile(optimizer = 'Adam', run_eagerly = True)\n","vae.fit(mnist_digits, epochs = 30, batch_size = 128) # 너무 오래걸려서 훈련 불가능"],"metadata":{"id":"AbdmTPD4nsWw"},"execution_count":null,"outputs":[]}]}