{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","machine_shape":"hm","authorship_tag":"ABX9TyORo2VphjoGhcaMtgfJIskC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["https://github.com/rickiepark/deep-learning-with-python-2nd/blob/main/chapter11_part03_transformer.ipynb\n"],"metadata":{"id":"xwWdUbKS5Rj_"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers"],"metadata":{"id":"97dupDfW1dX0","executionInfo":{"status":"ok","timestamp":1698908492822,"user_tz":-540,"elapsed":450,"user":{"displayName":"김태식","userId":"11264777984025639378"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","execution_count":15,"metadata":{"id":"0ViOyR79U50e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698908395672,"user_tz":-540,"elapsed":14134,"user":{"displayName":"김태식","userId":"11264777984025639378"}},"outputId":"38dab265-003a-4661-a226-be4b1d482c32"},"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 80.2M  100 80.2M    0     0  10.8M      0  0:00:07  0:00:07 --:--:-- 17.1M\n"]}],"source":["# IMDB 영화 리뷰 데이터 준비하기(원시 데이터)\n","!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","!tar -xf aclImdb_v1.tar.gz\n","\n"]},{"cell_type":"code","source":["!rm -r aclImdb/train/unsup # 필요없는 파일 삭제"],"metadata":{"id":"70v45R2LgNbz","executionInfo":{"status":"ok","timestamp":1698908398999,"user_tz":-540,"elapsed":999,"user":{"displayName":"김태식","userId":"11264777984025639378"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["import os, pathlib, shutil, random\n","\n","base_dir = pathlib.Path('aclImdb')\n","val_dir = base_dir / 'val' # val 폴더가 없어서 자동 생성\n","train_dir = base_dir / 'train' # train 폴더 가르키기\n","\n","for category in (\"neg\", \"pos\"):\n","    os.makedirs(val_dir / category) # val_dir안에 neg,pos폴더 생성\n","    files = os.listdir(train_dir / category) # train 폴더 안에는 neg,pos가 있음\n","    random.Random(1337).shuffle(files)\n","    num_val_samples = int(0.2 * len(files))\n","    val_files = files[-num_val_samples:] # 뒤에서 20% 뗌\n","    for fname in val_files:\n","        shutil.move(train_dir / category / fname,\n","                    val_dir / category / fname) # tarin폴더의 neg,pos 20%를 val폴더로 옮김\n"],"metadata":{"id":"UeiEHcA2gWS_","executionInfo":{"status":"error","timestamp":1698908402053,"user_tz":-540,"elapsed":569,"user":{"displayName":"김태식","userId":"11264777984025639378"}},"colab":{"base_uri":"https://localhost:8080/","height":386},"outputId":"0df6204b-48d9-467a-afef-713fb305e127"},"execution_count":17,"outputs":[{"output_type":"error","ename":"FileExistsError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-32a131073abe>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"neg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# val_dir안에 neg,pos폴더 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# train 폴더 안에는 neg,pos가 있음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1337\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'aclImdb/val/neg'"]}]},{"cell_type":"code","source":["# data set 생성\n","from tensorflow import keras\n","batch_size = 32\n","\n","train_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/train\", batch_size = batch_size)\n","\n","val_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/val\", batch_size = batch_size)\n","\n","test_ds = keras.utils.text_dataset_from_directory(\n","    \"aclImdb/test\", batch_size = batch_size)"],"metadata":{"id":"cI407HVdjS4u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698908428320,"user_tz":-540,"elapsed":2727,"user":{"displayName":"김태식","userId":"11264777984025639378"}},"outputId":"62b801cd-7a79-47f8-eb41-c6c72bf8e575"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 25000 files belonging to 2 classes.\n","Found 5000 files belonging to 2 classes.\n","Found 25000 files belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["\"\"\" 원시 텍스트(영어 댓글)을 TextVetorization으로 멀티-핫 인코딩된\n","이진 벡터로 변환한다.\"\"\"\n","from tensorflow.keras.layers import TextVectorization\n","text_vectorization = TextVectorization(\n","    max_tokens = 20000,\n","    output_mode = \"multi_hot\",\n",")\n","text_only_train_ds = train_ds.map(lambda x, y: x)\n","text_vectorization.adapt(text_only_train_ds)\n","binary_1gram_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls = 4)\n","binary_1gram_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls = 4)\n","binary_1gram_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls = 4)"],"metadata":{"id":"GzPzZWM5n8-G","executionInfo":{"status":"ok","timestamp":1698902421063,"user_tz":-540,"elapsed":2717,"user":{"displayName":"김태식","userId":"11264777984025639378"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["\"\"\" 단순한 모델 생성 함수\"\"\"\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","def get_model(max_token = 20000, hidden_dim = 16):\n","    inputs = keras.Input(shape = (max_token,))\n","    x = layers.Dense(hidden_dim, activation = 'relu')(inputs)\n","    x = layers.Dropout(0.5)(x)\n","    outputs = layers.Dense(1, activation = 'sigmoid')(x) # 감성분류\n","    model = keras.Model(inputs, outputs)\n","    model.compile(optimizer = 'rmsprop',\n","                  loss = 'binary_crossentropy',\n","                  metrics = ['accuracy'])\n","    return model"],"metadata":{"id":"JzQchdEDqml6","executionInfo":{"status":"ok","timestamp":1698902429815,"user_tz":-540,"elapsed":437,"user":{"displayName":"김태식","userId":"11264777984025639378"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["model = get_model()\n","model.summary()\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint('binary_1gram.h5',\n","                                    save_best_only = True)\n","]\n","model.fit(binary_1gram_test_ds.cache(),\n","          validation_data = binary_1gram_val_ds.cache(),\n","          epochs = 10,\n","          callbacks = callbacks)\n","\n","model = keras.models.load_model('binary_1gram.h5')\n","print(f\"테스트 정확도: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")\n","# 유니그램(1그램 모델) : 0.923"],"metadata":{"id":"H4r_zvlbrMYQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# N-그램 만들기 the cat is good -> N = 2일때 (the,cat) (cat,is) (is,good)\n","\n","from tensorflow.keras.layers import TextVectorization\n","text_vectorization = TextVectorization(\n","    ngrams = 5,\n","    max_tokens = 20000,\n","    output_mode = \"multi_hot\",\n",")\n","text_only_train_ds = train_ds.map(lambda x, y: x)\n","text_vectorization.adapt(text_only_train_ds)\n","binary_1gram_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls = 4)\n","binary_1gram_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls = 4)\n","binary_1gram_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls = 4)\n","\n","model = get_model()\n","model.summary()\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint('binary_5gram.h5',\n","                                    save_best_only = True)\n","]\n","model.fit(binary_1gram_test_ds.cache(),\n","          validation_data = binary_1gram_val_ds.cache(),\n","          epochs = 10,\n","          callbacks = callbacks)\n","\n","model = keras.models.load_model('binary_5gram.h5')\n","print(f\"테스트 정확도: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")\n","# 2그램 모델 : 0.937\n","# 3그램 모델 : 0.929\n","# 5그램 모델 : 0.934"],"metadata":{"id":"6NVl_ml6tJ32"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\" TF-IDF (단어 빈도-역문서 빈도) 정규화 시도 한 문장에 한 단어가 많이 등장할수록\n","그 단어는 중요한 것이지만, 문서 전체에서 많이 등장하는 단어 the, a, is 같은 단어들은\n","크게 중요하지 않기 때문에 그것을 고려한 측정 방법\"\"\"\n","\n","from tensorflow.keras.layers import TextVectorization\n","text_vectorization = TextVectorization(\n","    ngrams = 3,\n","    max_tokens = 20000,\n","    output_mode = \"tf_idf\",\n",")\n","text_only_train_ds = train_ds.map(lambda x, y: x)\n","text_vectorization.adapt(text_only_train_ds)\n","tfidf_3gram_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls = 4)\n","tfidf_3gram_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls = 4)\n","tfidf_3gram_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls = 4)\n","\n","model = get_model()\n","model.summary()\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint('tfidf_3gram.h5',\n","                                    save_best_only = True)\n","]\n","model.fit(tfidf_3gram_train_ds.cache(),\n","          validation_data = tfidf_3gram_val_ds.cache(),\n","          epochs = 10,\n","          callbacks = callbacks)\n","\n","model = keras.models.load_model('tfidf_3gram.h5')\n","print(f\"테스트 정확도: {model.evaluate(tfidf_3gram_test_ds)[1]:.3f}\")\n","# TF-IDF 3gram 모델 : 0.863 / 보통 1%의 상승을 불러오긴 함"],"metadata":{"id":"5Ad7AEKdu9oC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"순서 기반의 특성을 알아서 학습하는 시퀀스 모델,\n","1. 입력 샘플을 정수 인덱스로 변환한다\n","2. 각 정수를 벡터로 매핑하여 벡터 시퀀스를 얻는다 (TextVectorization)\n","3. 1D 컨브넷, RNN, 트랜스포머에 벡터 시퀀스를 전달한다. \"\"\"\n","\n","from tensorflow.keras import layers\n","\n","max_length = 600\n","max_tokens = 20000\n","text_vectorization = layers.TextVectorization(\n","    max_tokens = max_tokens,\n","    output_mode = 'int',\n","    output_sequence_length = max_length) # 600개 단어 이후로 자름\n","text_vectorization.adapt(text_only_train_ds)\n","\n","int_train_ds = train_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls = 4)\n","int_val_ds = val_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls = 4)\n","int_test_ds = test_ds.map(\n","    lambda x, y: (text_vectorization(x), y),\n","    num_parallel_calls = 4)"],"metadata":{"id":"T5nQJShXwn9p","executionInfo":{"status":"ok","timestamp":1698902642003,"user_tz":-540,"elapsed":3064,"user":{"displayName":"김태식","userId":"11264777984025639378"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["\"\"\" 원-핫 인코딩된 벡터 시퀀스로 시퀀스 모델 만들기\"\"\"\n","import tensorflow as tf\n","\n","inputs = keras.Input(shape = (None,), dtype = 'int64') # 입력은 정수 시퀀스\n","embedded = tf.one_hot(inputs, depth = max_tokens) # 정수를 2만 차원의 이진벡터로 인코딩\n","x = layers.Bidirectional(layers.LSTM(32))(embedded) # 양방향 LSTM\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation = 'sigmoid')(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer = 'rmsprop',\n","              loss = 'binary_crossentropy',\n","              metrics = ['accuracy'])\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint('one_hot_bidir_lstm.keras',\n","                                    save_best_only = True)\n","]\n","model.fit(int_train_ds, validation_data = int_val_ds, epochs = 10,\n","          callbacks = callbacks)\n","\n","model = keras.models.load_model('one_hot_bidir_lstm.keras')\n","print(f\"테스트 정확도 : {model.evaluate(int_test_ds)[1]:.3f}\")\n","# 속도가 너무 느림!"],"metadata":{"id":"c_JTAGR21OAM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\" 제로마스킹을 활용한 임베딩을 사용한 모델 \"\"\"\n","inputs = keras.Input(shape = (None,), dtype = 'int64')\n","embedded = layers.Embedding(\n","    input_dim = max_tokens, output_dim = 256, mask_zero = True)(inputs)\n","x = layers.Bidirectional(layers.LSTM(32))(embedded)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation = 'sigmoid')(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(optimizer = 'rmsprop',\n","              loss = 'binary_crossentropy',\n","              metrics = ['accuracy'])\n","model.summary()\n","\n","callbacks= [\n","    keras.callbacks.ModelCheckpoint('maksed_embeddings_bidir_lstm.h5',\n","                                    save_best_only = True)\n","]\n","model.fit(int_train_ds, validation_data = int_val_ds, epochs= 10,\n","          callbacks = callbacks)\n","model = keras.models.load_model('maksed_embedding_diblr_lstm.h5')\n","print(f\"테스트 정확도 : {model.evaluate(int_test_ds)[1]:.3f}\")\n","# 조금 느림"],"metadata":{"id":"RDHTsWmy7Sjh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\" 사전 훈련된 임베딩 GloVe 사용해보기\"\"\"\n","!wget http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip -q glove.6B.zip"],"metadata":{"id":"d4bhLahfg-MG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np # glove 파일 파싱하기\n","\n","path_to_glove_file = 'glove.6B.100d.txt'\n","embeddings_index = {}\n","with open(path_to_glove_file) as f:\n","    for line in f:\n","        word, coefs = line.split(maxsplit = 1)\n","        coefs = np.fromstring(coefs, 'f', sep=' ')\n","        embedding_index[word] = coefs\n","\n","print(f\"단어 벡터 개수: {len(embedding_index)}\") # 40만개"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zNGn4dmXhKJy","executionInfo":{"status":"ok","timestamp":1698904050537,"user_tz":-540,"elapsed":6530,"user":{"displayName":"김태식","userId":"11264777984025639378"}},"outputId":"c9f266aa-d2a3-4a54-ca09-dfe21f1a0096"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["단어 벡터 개수: 400000\n"]}]},{"cell_type":"code","source":["#glove 단어 임베딩 행렬 준비하기\n","embedding_dim = 100\n","\n","vocabulary = text_vectorization.get_vocabulary() # keras layer\n","word_index = dict(zip(vocabulary, range(len(vocabulary)))) # 사전에 있는 단어와 인덱스 매핑\n","\n","embedding_matrix = np.zeros((max_tokens, embedding_dim))\n","for word, i in word_index.items():\n","    if i < max_tokens:\n","        embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector\n","\n","# 이것또한 그렇게 큰 성능 향상을 가져오지 않음."],"metadata":{"id":"pGx1VNGuj8mf","executionInfo":{"status":"ok","timestamp":1698904052933,"user_tz":-540,"elapsed":805,"user":{"displayName":"김태식","userId":"11264777984025639378"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Tranformer 기본\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","        super().__init__(*kwargs)\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention = layers.MutilHeadAttention(\n","            num_heads = num_heads, key_dim = embed_dim)\n","        self.dense_proj = keras.Sequential(\n","            [layers.Dense(dense_dim, activation = 'relu'),\n","             layers.Dense(embed_dim),]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","\n","    def call(self, inputs, mask = None):\n","        if mask is not None:\n","            mask = mask[:, tf.newaxis, :]\n","        attention_output = self.attention(\n","            inputs, inputs, attention_mask = mask)\n","        proj_input = self.layernorm_1(inputs + attention_output)\n","        proj_output = self.dense_proj(proj_input)\n","        return self.layernorm_2(proj_input, proj_output)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"embed_dim\": self.embed_dim,\n","            \"num_heads\": self.num_heads,\n","            \"dense_dim\": self.dense_dim,\n","        })\n","        return config\n"],"metadata":{"id":"Gi6EjtiK0LXZ","executionInfo":{"status":"ok","timestamp":1698908981216,"user_tz":-540,"elapsed":453,"user":{"displayName":"김태식","userId":"11264777984025639378"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KwArpz8D3dBx"},"execution_count":null,"outputs":[]}]}